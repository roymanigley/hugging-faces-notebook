{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fc81af-e8a0-41ef-b0ad-616fc75c1943",
   "metadata": {},
   "source": [
    "# Hugging Faces Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932e658-328a-483f-a63e-af163b2c9977",
   "metadata": {},
   "source": [
    "## Language detection\n",
    "> langua detection experiment using 'papluca/xlm-roberta-base-language-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ead6697a-4f15-42e9-a8e0-03d66fed7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bd1f38-f60c-422a-8030-b4d4532bec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"papluca/xlm-roberta-base-language-detection\",\n",
    "    device=torch.device('cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd2b28b6-3817-4cec-9b1a-3c2c1f4cb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 4.99k/4.99k [00:00<00:00, 4.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/papluca--language-identification to /root/.cache/huggingface/datasets/papluca___csv/papluca--language-identification-ad5bdc8c9b1a4985/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/12.0M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   0%|          | 44.0k/12.0M [00:00<00:42, 277kB/s]\u001b[A\n",
      "Downloading data:   2%|▏         | 288k/12.0M [00:00<00:12, 936kB/s] \u001b[A\n",
      "Downloading data:   7%|▋         | 799k/12.0M [00:00<00:05, 2.18MB/s]\u001b[A\n",
      "Downloading data:  16%|█▋        | 1.96M/12.0M [00:00<00:01, 5.07MB/s]\u001b[A\n",
      "Downloading data:  29%|██▉       | 3.45M/12.0M [00:00<00:01, 8.06MB/s]\u001b[A\n",
      "Downloading data:  43%|████▎     | 5.10M/12.0M [00:00<00:00, 10.6MB/s]\u001b[A\n",
      "Downloading data:  60%|█████▉    | 7.17M/12.0M [00:00<00:00, 13.6MB/s]\u001b[A\n",
      "Downloading data:  77%|███████▋  | 9.21M/12.0M [00:00<00:00, 15.6MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 12.0M/12.0M [00:01<00:00, 10.9MB/s]\u001b[A\n",
      "Downloading data files:  33%|███▎      | 1/3 [00:02<00:04,  2.22s/it]\n",
      "Downloading data:   0%|          | 0.00/1.69M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   6%|▌         | 99.3k/1.69M [00:00<00:02, 567kB/s]\u001b[A\n",
      "Downloading data:  21%|██▏       | 361k/1.69M [00:00<00:00, 1.43MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 1.69M/1.69M [00:00<00:00, 3.50MB/s]\u001b[A\n",
      "Downloading data files:  67%|██████▋   | 2/3 [00:03<00:01,  1.43s/it]\n",
      "Downloading data:   0%|          | 0.00/1.71M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:   7%|▋         | 116k/1.71M [00:00<00:01, 1.16MB/s]\u001b[A\n",
      "Downloading data:  25%|██▌       | 427k/1.71M [00:00<00:00, 2.23MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 1.71M/1.71M [00:00<00:00, 4.15MB/s][A\n",
      "Downloading data files: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 1051.91it/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]/usr/local/lib/python3.8/dist-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n",
      "Generating test split: 0 examples [00:00, ? examples/s]             /usr/local/lib/python3.8/dist-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n",
      "Generating validation split: 0 examples [00:00, ? examples/s]/usr/local/lib/python3.8/dist-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n",
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/papluca___csv/papluca--language-identification-ad5bdc8c9b1a4985/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 293.87it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('papluca/language-identification', split=['train[0:10]', 'test[0:10]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473013da-570a-47e4-b841-420b2ba5ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   labels  10 non-null     object\n",
      " 1   text    10 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>nl</td>\n",
       "      <td>Een man zingt en speelt gitaar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                             text\n",
       "count      10                               10\n",
       "unique      7                               10\n",
       "top        nl  Een man zingt en speelt gitaar.\n",
       "freq        3                                1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ds[1])\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769ac95e-ee44-47ad-9344-645394f16885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = df[df.labels.isin(['de', 'en', 'fr', 'it'])].head(50)['text'].values.tolist()\n",
    "test_labels = df[df.labels.isin(['de', 'en', 'fr', 'it'])].head(50)['labels'].values.tolist()\n",
    "len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c9f275c-d5ab-48fb-93b4-c555c631e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_validate = model(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df1f8a4e-6ea8-4eb5-ace5-c0f950023859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([[i['label'] for i in to_validate], test_labels])\n",
    "plt.legend(['expected', 'actual'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "497120ca-e7f1-4ba8-9531-baab3bdb134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(to_validate)):\n",
    "    if to_validate[i]['label'] not in ['it', 'fr', 'en', 'de']:\n",
    "        print('predicted:', to_validate[i]['label'], '| expedted:', test_labels[i], '| text:', test_text[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96416f8-3b3c-4ff5-9d23-a2fcbc2812da",
   "metadata": {},
   "source": [
    "## Train existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a75980d-5366-4d73-891f-c89237631282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, Trainer, AutoModelForSequenceClassification, XLMRobertaForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9f6d2d-a7be-4552-85ab-8cb19d9954df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('papluca/xlm-roberta-base-language-detection')\n",
    "def tokenize(data):\n",
    "    return tokenizer(data['text'], truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851c590e-f9a4-4de2-8cce-d62a04fca2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/papluca___csv/papluca--language-identification-ad5bdc8c9b1a4985/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|██████████| 2/2 [00:00<00:00, 99.22it/s]\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/papluca___csv/papluca--language-identification-ad5bdc8c9b1a4985/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-423cf3fc6fb120f0.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/papluca___csv/papluca--language-identification-ad5bdc8c9b1a4985/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-b807b8e3beae6bbb.arrow\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('papluca/language-identification', split=['train[0:10]', 'test[0:10]'])\n",
    "train_tokenized_dataset = ds[0].map(tokenize)\n",
    "test_tokenized_dataset = ds[1].map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4c8dc8-cde2-4fe9-829d-9895a8ccc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7188b964-6ca2-47ef-9fcd-8b545202d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de5285d-e64c-42c7-ba7b-f05c0ec24598",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=test_tokenized_dataset,\n",
    "    optimizers=(optimizer, None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db656cb4-81fc-4d4d-92b1-265f1dd17f0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1905\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1906\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1907\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1908\u001b[0m ):\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:2644\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2643\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2644\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2647\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:2689\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[0;32m-> 2689\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2690\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2691\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2692\u001b[0m         )\n\u001b[1;32m   2693\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[1;32m   2694\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e453bc5-d569-42d0-b6a2-716ee81249ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
